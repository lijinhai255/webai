import streamlit as st
from langchain.schema import HumanMessage

# ä» LLM ç›®å½•å¯¼å…¥å„æ¨¡å‹
from LLM.chat_glm4 import ChatGLM4
from LLM.chat_glm4v import ChatGLM4V
from LLM.cogview3 import ChatCogView3
from LLM.cogvideox import ChatCogVideoX

# âœ… åˆå§‹åŒ– LLM
llm_models = {
    "GLM-4 Flashï¼ˆæ–‡æœ¬ï¼‰": ChatGLM4(),
    "GLM-4V Flashï¼ˆå›¾åƒç†è§£ï¼‰": ChatGLM4V(),
    "CogView-3 Flashï¼ˆå›¾åƒç”Ÿæˆï¼‰": ChatCogView3(),
    "CogVideoX Flashï¼ˆè§†é¢‘ç”Ÿæˆï¼‰": ChatCogVideoX()
}

# âœ… Streamlit é¡µé¢å¸ƒå±€
st.title('ğŸ’¡ AI å¤šæ¨¡å‹ Chatbot')

# é€‰æ‹©æ¨¡å‹
model_choice = st.selectbox("è¯·é€‰æ‹©æ¨¡å‹ï¼š", list(llm_models.keys()))
selected_llm = llm_models[model_choice]

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "video_task_id" not in st.session_state:
    st.session_state.video_task_id = None

# æ˜¾ç¤ºèŠå¤©å†å²è®°å½•
for chat in st.session_state.chat_history:
    with st.chat_message(chat["role"]):
        if chat["type"] == "å›¾ç‰‡":
            st.image(chat["content"], caption="AI ç”Ÿæˆçš„å›¾ç‰‡", use_container_width=True)
        elif chat["type"] == "è§†é¢‘":
            st.video(chat["content"])
        else:
            st.markdown(chat["content"])

# ç”¨æˆ·è¾“å…¥æ¡†
user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„æ¶ˆæ¯...")

if user_input:
    st.session_state.chat_history.append({"role": "user", "content": user_input, "type": "text"})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()

        # A) å¤„ç†æ–‡æœ¬/å›¾åƒç†è§£
        if isinstance(selected_llm, (ChatGLM4, ChatGLM4V)):
            response_text = ""
            for chunk in selected_llm.stream([HumanMessage(content=user_input)]):
                response_text += str(chunk)
                response_placeholder.write(response_text)
            st.session_state.chat_history.append({"role": "assistant", "content": response_text, "type": "text"})

        # B) å¤„ç†å›¾åƒç”Ÿæˆ
        elif isinstance(selected_llm, ChatCogView3):
            image_url = selected_llm.invoke(user_input)
            st.image(image_url, caption="AI ç”Ÿæˆçš„å›¾ç‰‡", use_container_width=True)
            st.session_state.chat_history.append({"role": "assistant", "content": image_url, "type": "å›¾ç‰‡"})

        # C) å¤„ç†è§†é¢‘ç”Ÿæˆ
        elif isinstance(selected_llm, ChatCogVideoX):
            task_id = selected_llm.invoke(user_input)
            if task_id.startswith("âŒ"):
                st.error(task_id)
            else:
                st.session_state.video_task_id = task_id
                st.info(f"â³ è§†é¢‘ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ ID: {task_id}ï¼Œè¯·ç¨åæŸ¥è¯¢çŠ¶æ€ã€‚")

# è§†é¢‘æŸ¥è¯¢æŒ‰é’®
if st.session_state.video_task_id:
    if st.button("ğŸ” æŸ¥è¯¢è§†é¢‘çŠ¶æ€"):
        with st.spinner("æŸ¥è¯¢ä¸­..."):
            video_result = selected_llm.get_video_result(st.session_state.video_task_id)
            if "video_url" in video_result:
                st.video(video_result["video_url"])
                st.image(video_result["cover_url"], caption="ğŸ¬ è§†é¢‘å°é¢")
                st.session_state.chat_history.append({"role": "assistant", "content": video_result["video_url"], "type": "è§†é¢‘"})
                st.session_state.video_task_id = None
            elif "error" in video_result:
                st.error(video_result["error"])
